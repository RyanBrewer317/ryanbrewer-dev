<html lang="en"><head><script async="true" src="https://www.googletagmanager.com/gtag/js?id=G-BDZJ8SX3Y1"></script><script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
        </script><title>Implicit Products: A Better Type-Theoretic &quot;Forall&quot; - Ryan Brewer</title><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Implicit products are a fascinating approach to universal quantification in dependent type theory, as well as proof irrelevance/erasure in compiler implementation."><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="alternate" type="application/rss+xml" title="Ryan Brewer's Blog" href="https://ryanbrewer.dev/feed.rss"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="true"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto&display=swap"><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type="text/javascript" async="true" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script><script>hljs.highlightAll();</script>  <script type="module" crossorigin src="/assets/style-d8333133.js"></script>
  <link rel="stylesheet" href="/assets/style-5cc4213c.css">
</head><body><nav><a href="/" id="nav-home">Ryan Brewer</a><a href="/search" id="nav-search">Posts</a><a href="/contact.html" id="nav-contact">Contact</a><a href="/feed.rss" id="nav-subscribe"><img src="/rss-icon.png" id="rss-subscribe-icon">Subscribe</a></nav><div id="body"><h1>Implicit Products: A Better Type-Theoretic &quot;Forall&quot;</h1><div class="date">December 10, 2023</div><p>In this post I&#39;ll talk about a type theory idea that deserves more attention: implicit products.
They came about in the 1998 dissertation of Alexandre Miquel, 
but for English speakers a common citation would be 
<a href="https://www.semanticscholar.org/paper/The-Implicit-Calculus-of-Constructions-Extending-an-Miquel/990f8f44e011192122dfd35617f8cabf08052d60">The Implicit Calculus of Constructions</a>.
They are used most notably in the <a href="https://cedille.github.io/">Cedille</a> proof assistant.
</p><p>This post assumes familiarity with logic (including the universal quantifer &quot;for all&quot;), 
<a href="/posts/logic-in-types.html">dependent types</a>, very basic set theory, and the \(\lambda\)-calculus.
</p><h3>What is it?
</h3><p>For a moment, you&#39;ll have to ignore the strange name <i>implicit product.</i>
It makes a lot of sense once you know how they&#39;re used, but I&#39;ll get to that later.
Think of an implicit product like a universal quantifer (&quot;for all&quot;) in logic.
It&#39;s written like:
</p><div><div class="math-block">\[\forall x: A. B(x)\]</div><div class="math-block">\[\]</div></div><p>where \(A\) is a type (proposition) and \(B\) is a type that may refer to \(x\) (predicate).
An implicit product is a type that is inhabited if \(B(x)\) is inhabited for every \(x\) in \(A\).
</p><p>In the most recent iterations of the theory, you make a value of this type by writing \(\Lambda x: A. e\)
where, crucially, \(x\) can appear in the types in \(e\) but not in anything that could stick around &#39;til runtime.
That is, if you erase all the types of \(e\), the \(x\) isn&#39;t used in it at all.
To use such a term \(\Lambda x: A. e\) you call it like a \(\lambda\)-abstraction.
For the purpose of type-inference you might mark the call with some additional symbol to make it clear
that the function is a \(\Lambda\)-abstraction and not a \(\lambda\)-abstraction.
</p><h3>Infinite Intersection
</h3><p>On the surface this might just seem like a worse \(\Pi\)-type, which is the usual &quot;for all&quot; in something
like Coq, Agda, or Lean. 
The only real difference, from what I&#39;ve said so far, is that the parameter of the abstraction isn&#39;t used at runtime. 
But this makes all the difference. 
</p><p>A \(\Pi\)-type represents &quot;for all&quot; in a strange, roundabout way: it&#39;s a function (implication) from <i>data</i> (not a proposition)
to a proposition about that data, and can only be constructed if every proposition it returns can be constructed given the data of that
proposition.
</p><p>When you learn about &quot;for all&quot; and &quot;there exists&quot; in logic, that isn&#39;t at all how you normally learn it.
Instead, &quot;for all&quot; is seen as a possibly-infinite conjunction for every element of a possibly-infinite domain.
&quot;There exists&quot; is, dually, a possibly-infinite <i>disjunction</i> for every element of a possibly-infinite domain.
\(\Sigma\)-types can kind of be seen that way for existential quantification, but \(\Pi\)-types definitely can&#39;t,
because again, they&#39;re a bit like an implication from a non-proposition.
They work for doing logic, of course; they&#39;re just a little weird.
</p><p>Implicit products fix this. 
An implicit product is a possibly-infinite <i>intersection</i> (conjunction) of all the possible &quot;return types.&quot;
\(\forall x: A. B(x)\) is an intersection of all types \(B(x)\) for each \(x\) in \(A\).
</p><p>What&#39;s an intersection type? 
They&#39;re what you get when you say that a term (say, \(e\)) could have one type (say, \(A\)) or another type (say, \(B\)).
Then you might say \(e: A\cap B\), that is, \(e\) is in the <i>intersection</i> between the types \(A\) and \(B\).
This isn&#39;t the standard way of doing conjunction in logic (pairs/structs/records/tuples are), 
but it should be clear that if \(A\cap B\) has a value in it (and is therefore &quot;true&quot;), 
then \(A\) and \(B\) also have values in them (are &quot;true&quot;), namely that same value in their intersection.
So it acts like a conjunction here.
</p><p>But wait, if it&#39;s just an intersection of all the return types, it&#39;s not really a function, right?
How is that possible? We literally have calls to \(\Lambda\)-abstractions!
The secret is, since they don&#39;t use their parameter for evaluation, it&#39;s perfectly fine to evaluate them with no argument at all!
(In the absense of side-effects, of course.)
At runtime, \((\Lambda x: A. \lambda y: B. e)(a)(b)\) evaluates as \((\lambda y. e)(b)\). 
Therefore, values of type \(\forall x: A. B(x)\) execute as some kind of \(B\), 
and we know that its argument (\(x\)) doesn&#39;t matter.
</p><p>Implicit products are generalization in their truest form: some aspect of a value could work for multiple types,
so the type gets replaced with a type variable, and the whole type becomes an intersection of all the possible
instantiations of that type variable. 
This is why I argue that implicit products make for a &quot;better&quot; interpretation of the universal quantifier than \(\Pi\)-types.
</p><h3>What&#39;s with that name though?
</h3><p>The other reason implicit products are interesting is from a compiler engineering perspective.
When developing a dependently typed language, a huge optimization to make is erasing the proofs at runtime,
much like one erases the types at runtime. 
The only thing that should remain are values of actual <i>data</i>types, like <code>int</code>, 
as opposed to proofs of propositions (which are technically still values of types).
</p><p>To that end, languages like Idris and Agda, and the extraction of OCaml code from Coq code, 
have put a lot of effort into <i>proof irrelevance,</i> the property that proofs don&#39;t affect runtime execution.
Idris has Quantitative Type Theory for this, which allows it to say that the variables bound by some 
\(\lambda\)-abstractions aren&#39;t used &quot;relevantly&quot; in the body of the abstraction. 
That is, it can be used in things that get erased, but nothing that makes it to runtime.
Sound familiar? These &quot;0-quantity&quot; \(\lambda\)-abstractions are very similar to implicit products.
The only real difference is that they&#39;re philosophically still functions, not giant intersections.
The erasure of the argument is an optimization, nothing more. 
Regardless, this similarity shows how using implicit products in your language automatically gives you a big optimization.
</p><p>The &quot;0-quantity&quot; \(\lambda\)-abstractions of Idris&#39; QTT are called &quot;implicit.&quot;
This is a common term for arguments that we expect to disappear at runtime.
There is the risk of confusion with another meaning for &quot;implicit&quot; in this context:
arguments which you <i>don&#39;t</i> write but which (possibly) <i>are</i> present at runtime.
This kind of &quot;implicit&quot; is a basic form of type inference for dependently typed languages.
If you have a polymorphic identity function \(id=\lambda t: *.\lambda x: t. x\) then
you&#39;d like to be able to call it like \(id(7)\) instead of \(id(\mathbb{N})(7)\), but
you would consider this a notational shorthand, nothing more.
That&#39;s called an &quot;implicit&quot; argument but it isn&#39;t the type of &quot;implicit&quot; we consider here for implicit products.
</p><p>So now we know why they&#39;re called <i>implicit</i> products.
Why are they called implicit <i>products?</i>
</p><p>This might be a more basic point for those quite familiar with dependent types,
but it&#39;s an easy source of confusion so I figured I&#39;d touch on it anyway.
In general in type theory, a product is a type of tuple: 
the product of \(\mathbb{N}\) and \(\mathbb{Z}\) is the type of pairs of natural numbers and integers,
and is written \(\mathbb{N}\times\mathbb{Z}\). 
It&#39;s a Cartesian product, to use a term more broadly familiar.
This is really confusing because \(\Pi\)-types are often referred to as &quot;products,&quot;
or &quot;dependent product types,&quot; as well as being called &quot;dependent function types.&quot;
My understanding for why this is the case is that we can think of a tuple (an element of a product type) as a function from
\(\mathbb{N}\) to values of various types. 
These are &quot;indexed&quot; by the natural number given.
So \((5, {4})\) is a tiny function mapping \(0\) to \(5\) and \(1\) to \({4}\).
The return type of this function depends on the integer given as its argument: it&#39;s a dependent function type!
A \(\Pi\)-type indexes values of various types (the family of return types) using the values of the argument type.
It is this function-type meaning of &quot;product&quot; that is used in the term &quot;implicit product.&quot;
</p><h3>Conclusion
</h3><p>That&#39;s all I have to say about implicit products for now.
I think they&#39;re a really cool idea and I&#39;m adding them to my own dependently-typed language
<a href="https://github.com/RyanBrewer317/Saber">Saber</a>.
If you want to play with a finished implemenation, though,
the most famous by far would be <a href="https://cedille.github.io/">Cedille</a>.
</p></div><div><div style="height:100pt;"></div><script src="/__/firebase/8.10.1/firebase-app.js"></script><script src="/__/firebase/8.10.1/firebase-analytics.js"></script><script src="/__/firebase/init.js"></script><script>firebase.analytics();</script></div></body></html>