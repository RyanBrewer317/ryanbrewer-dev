id: getting-started-category-theory
name: Getting Started with Category Theory
date: 2024-07-20
tags: intro,introduction,getting,started,category,theory,categories,object,objects,morphism,morphisms,functor,functors,natural,transformation,transformations
description: Category theory is a beautiful and powerful field but it can feel impenetrable without the right entry point. This post hopes to serve as a sort of beginner's guide.

@paragraph@
Category theory is a fascinating and unreasonably powerful tool for thinking about computation, transformation, and relationships between things in the world. That makes it useful for mathematicians, computer scientists, and philosophers alike. I've struggled through learning a decent chunk of the theory on my own (meaning, no university courses) and now that I have a couple years of that struggle behind me I thought I should document some of the really useful intuitions and perspectives on category theory that made everything make sense for me but which aren't really discussed in any materials I came across. This post will be a bit long, acting as a whirlwind tour of many important concepts.
@end@

@paragraph@
I often find that the most useful and time-saving thing I do when learning category theory is to get out a pencil and paper and sketch the concepts in any way that makes sense to me. The teaching benefits massively from the combination of seeing things organized two-dimensionally and figuring out enough to be able to draw anything in the first place. I recommend you draw out example diagrams and tables as you read through this post, though I'll try to make that as unnecessary as I can. With this many ideas, it can be valuable to take your time getting through the post.
@end@

@subheading@
What's a category?
@end@

@paragraph@
If you feel like you already know what a category is, you might still get value from this section, as I tried to fill it with all the intuition, philosophy, advice, and perspective that has helped me so far.
@end@

@paragraph@
Informally, a category is just a collection of things, along with a particular relationship between these things. For example, imagine the collection of all possible states our world could be in (Einstein being the American president, dogs not existing, and any other wacky thing you can come up with). In any particular world \\(W_1\\), there are other worlds \\(W_2\\) that we can "get to" if some sequence of events were to occur, transforming \\(W_1\\) into \\(W_2\\). At the very least, every state can "get to" *itself* by "doing nothing." For example, I can get from a world where I have an apple to a world where I don't by eating the apple, or giving it away, or throwing it in a lake, etc.
@end@

@paragraph@
Formally, a category \\(C\\) is a collection of objects (often written \\(\\texttt{ob}(C)\\)) and a collection of arrows (often called "morphisms," each starting at an object and ending at an object). To be a valid category, there are some requirements these collections need to satisfy. *It's very helpful to draw these on paper.* For any object \\(X\\) in \\(C\\), there must be a morphism from \\(X\\) to \\(X\\) (drawn as a little loop at \\(X\\)) that "does nothing" (typically written \\(id_X\\) but sometimes unfortunately written as just \\(X\\) when what is meant is "clear from context"). This is called an "identity arrow," "identity on \\(X\\)," or "identity of \\(X\\)." Also, for any objects \\(X\\), \\(Y\\), and \\(Z\\) in \\(C\\), for any two morphisms \\(f:X\\to Y\\) and \\(g:Y\\to Z\\), there must be a morphism \\(g\\circ f:X\\to Z\\) (pronounced "\\(g\\) after \\(f\\)") that is exactly the same as following \\(f\\) from \\(X\\) to \\(Y\\) and from there following \\(g\\) to finally get to \\(Z\\). This is called the *composition* of \\(f\\) and \\(g\\), and the composition operator \\(\\circ\\) must be associative. These requirements are drawn formally with the following diagrams. These diagrams are called "commutative diagrams" or "commuting diagrams," meaning that any two paths from one object to another must be equal (one says the diagram "commutes"). Therefore, each diagram is visually representing a bunch of equations, such as \\(f\\circ id_X=f\\).
@end@

@diagram@
    X\ar[r, "f"] & Y\ar[loop right, "id_Y"]
@end@

@diagram@
    X\ar[loop left, "id_X"]\ar[r, "f"] & Y
@end@

@diagram@
    X\ar[r, "f"]\ar[rr, "g\circ f", bend left=30] & Y\ar[r, "g"]\ar[rr, "h\circ g", bend right=30] & Z\ar[r, "h"] & W
@end@

@paragraph@
These requirements aren't too difficult to satisfy; categories show up all over the place. Any transitive, reflexive relation (these are called "preorders") gives rise to a category, including \\(\\leq\\) on the integers. So for any integer, say \\(7\\), it's less than or equal to itself (\\(7\\leq 7\\)). And for any three integers \\(a\\), \\(b\\), and \\(c\\), if \\(a\\leq b\\) and \\(b\\leq c\\), then \\(a\\leq c\\). And of course, \\(\\leq\\) is associative.
@end@

@paragraph@
You'll also find a category in any "monoid," that is, an associative binary operation (like \\(+\\)) on a set (like the integers) which has a unit for the operation (like \\(0\\)). You can form a category with a single object \\(M\\) where the arrows all loop from \\(M\\) back to \\(M\\), representing the elements of the set (such as the integers). So for example, \\(1:M\\to M\\), \\(2:M\\to M\\), etc. \\(M\\) is called a "monoid object." This is a proper category because any two of these arrows can be composed using the binary operation, which we've required to be associative. For example, \\(3+4:M\\to M\\). And there's an arrow for the unit (such as \\(0\\), for \\(+\\)) that behaves as the identity arrow of \\(M\\).
@end@

@paragraph@
*Psst-- Draw those examples out on a sheet of paper! Show some example diagrams! It really helps ideas crystallize. Here's one:*
@end@

@diagram@
    M\ar[loop left, "3"]\ar[loop right, "4"]\ar[loop below, "7"]\ar[loop above, "0"]
@end@

@paragraph@
It's been said in some category theory learning material that I can't find now that a category is something like a bridge between the definition of a preorder and the definition of a monoid, capturing each in a way that extends the other. This is an informal idea but I found it helpful. A preorder is a category with multiple objects but only one arrow (at most) between each object, and a monoid is a category with multiple arrows but only one object. Bartosz Milewski (a popular category theory educator) suggested that a category can also be seen as a "proof-relevant" preorder, meaning objects can be related to each other and themselves in multiple ways that are seen as distinct, as opposed to typical relations which either relate two given objects or don't.
@end@

@paragraph@
In programming, we typically use a slightly different-looking category. Namely, we typically use categories where the objects are types (or some similar collection, like sets) and the arrows are functions (or function-like in some way). That's why I've been naming objects uppercase and naming morphisms starting from "f." This particular kind of category has certain properties right out the gate. The "relationships" between objects aren't propositions (like \\(4\\leq 5\\)) but *transformations* (like \\(f(x)=x+1\\)). We often have values *within* objects (since the objects are collections), which wouldn't make sense with an object like \\(7\\). That means there are multiple distinct values, like \\(7\\) or \\(8\\), that are different from each other but represented by the same object in the category (say, `int`). Category theory can't talk about these values directly (it can hardly say things about even the *objects,* as it generally uses morphisms for all reasoning) though if you have something like a singleton set \\(S\\) then the set of all functions from \\(S\\) to any set \\(X\\) is equivalent to the set \\(X\\) itself, and gives a way of talking about the elements of \\(X\\) in category theory. Categories where the objects are collections are *EXTREMELY* powerful, and it's the main reason we say a category has a "collection" of objects instead of a "set;" we'd like to be able to construct categories where the objects are all the sets, and there's no set-of-all-sets so this category's objects don't form a set. "Small" categories are ones where the objects form a set, and "large" categories are the rest, and include many interesting and powerful categories I'll discuss later on. 
@end@

@paragraph@
I think these categories-of-collections are also very useful and underappreciated for analytic philosophers, which is why the first example category I gave was an analysis of possible worlds. That category is an example where objects have an enormous amount of information (the entire state of the world), and arrows are transformations (sequences of events).
@end@

@paragraph@
Another philosophical point is that we try whenever possible to avoid testing two objects for equality. Equality is seen as a philosophically problematic or even potentially ill-defined notion in the full generality of category theory. So, for example, it's important to talk about the composition law as "given objects \\(X\\), \\(Y\\), \\(Z\\), and morphisms \\(f:X\\to Y\\) and \\(g:Y\\to Z\\), there's a morphism \\(g\\circ f:X\\to Z\\) such that etc. etc." Instead of, "given morphisms \\(f:X\\to Y\\) and \\(g:Z\\to W\\), if \\(Y=Z\\) then there's a morphism \\(g\\circ f:X\\to W\\) etc." or anything like that. It's useful to note that there's nothing saying that \\(X\\), \\(Y\\), and \\(Z\\) have to be different from each other. Recall the monoid-based category, with only one object \\(M\\), where composition was between two arrows \\(f:M\\to M\\) and \\(g:M\\to M\\). The rules for identity arrows, like \\(id_Y\\circ f=f\\;\\) (for some \\(f:X\\to Y\\)), certainly apply when \\(X\\) and \\(Y\\) are the same object.
@end@

@paragraph@
A final philosophical point that's very important for getting any further in category theory is that one should be thinking in terms of the sets of morphisms from an object to another. These sets are called "homsets" and are written \\(C(X,Y)\\) for the set of arrows starting at \\(X\\) and ending at \\(Y\\) in the category \\(C\\). These sets are also written \\(\\texttt{Hom}(X,Y)\\). Category theory never wants to be talking about the details of a particular object; these should be seen as opaque and uninformative, even if they have a rich internal structure. Instead, the philosophy of category theory is that objects are completely described by the arrows going to and from them, and these arrows should be what you refer to when you want to say something about an object. Note that homsets run into the same "large" and "small" thing that collections objects do: when talking about the homsets of a category, one uses the term "local," so a "locally small" category is one where the collections of arrows between any two objects is always a set. Advanced category often "enriches" categories, a term that means using something besides sets for these collections, such as categories, but I'm getting ahead of myself!
@end@

@paragraph@
In many cases, the arrows of a category will also have some representation as objects in that same category. For example, in a category of sets and functions, functions are also sets, so may be present as both arrows and objects in the category. Categories where *every* arrow has a corresponding object are called "closed." The object of an arrow \\(f:X\\to Y\\) is called an "exponential" or "exponential object" and is written \\(Y^X\\). This notation comes from the idea that if \\(X\\) and \\(Y\\) are sets, the number of elements (functions) in the set \\(X\\to Y\\) is equal to the number of elements in \\(Y\\) raised to the power of the number of elements in \\(X\\), which is kinda fun I think. I won't properly define exponential objects until later on when I discuss products and universal constructions, but just knowing about them informally helps one realize the depth with which one can think about arrows in a category.
@end@

@subheading@
Category theory on category theory
@end@

@paragraph@
Now we have a bunch of definitions and intuition about what a category is, but the rest of the results of category theory are still impenetrable. That is, until we start thinking about *shifting perspectives.* Notice that when I gave an example of a category based on a preorder, the objects were the set of all integers. Then when I gave an example of a category based on a monoid, the *morphisms* were the set of all integers. It's the same set, but in one category they're objects and in another they're arrows! These kinds of shifts between different categories that describe the same thing in very different ways are all over the place in category theory.
@end@

@paragraph@
A particularly powerful example of this are categories where the *objects are categories.* These categories mean that when you're doing some work with a category, you're also working in larger categories where your category is an object, and those categories have arrows to and from your category that you can actually use to help with your reasoning. The primary example of this is called \\(\\texttt{Cat}\\), a large category where the objects are all small categories. The arrows in \\(\\texttt{Cat}\\) are called "functors," and they're functions (really *mappings,* in the event of a large or locally large category where they can't be functions) mapping objects of some category \\(C\\) into objects of some category \\(D\\), and mapping the arrows in \\(C\\) to arrows in \\(D\\). Functors also get an extra restriction: functors must preserve commuting diagrams. What this means is that composition and identity must be preserved: \\(F(g\\circ f)=Fg\\circ Ff\\) and \\(F(id_X)=id_{FX}\\). That's an important idea and worth thinking about a little, and hopefully will become more clear in the coming paragraphs. This restriction makes functors a sort of homomorphisms, if you're familiar with group theory or related fields of abstract algebra. In more friendly language, functors are required to preserve the structure of a category. So if I have some diagram in my category \\(C\\) then a functor \\(F:C\\to D\\) gives me a diagram in \\(D\\) that can be drawn in a very similar way: 
@end@

@paragraph@
@end@

@diagram@
    C            & X\ar[ddl,"p"']\ar[ddr,"q"] &              &                & FX\ar[ddl,"Fp"']\ar[ddr,"Fq"] & D  \\
                 &                            & {}\ar[r,"F"] & {}             &                               &    \\
    Y\ar[rr,"f"] &                            & Z            & FY\ar[rr,"Ff"] &                               & FZ
@end@

@paragraph@
@end@

@paragraph@
This does *not* mean that if \\(X\\), \\(Y\\), and \\(Z\\) are different from each other, then \\(FX\\), \\(FY\\), and \\(FZ\\) are too. It *only* means that, assuming the first diagram commutes, the second one does too. \\(FX\\) could be equal to \\(FY\\), and \\(Fp\\) could even just be \\(id_{FX}\\)! So long as commuting diagrams are mapped to diagrams that also commute. One example of a functor that I like is from the monoid-based category of addition on natural numbers to the monoid-based category of multiplication on natural numbers. The single monoid object gets mapped into the other single monoid object, of course. There are a bunch of functors to choose from here, but I like powers of 2 so I'll map every morphism \\(n\\) in the addition category to the morphism \\(2^n\\) in the multiplication category. That's a functor because if I compose two morphisms in the addition category (say, \\(2+3\\)) then does the right thing in the multiplication category:
@end@

@diagram@
    M_+\ar[loop left,"3"]\ar[loop below,"2"]\ar[loop above,"2+3=5"] & {}\ar[r,"F"] & {} & M_\cdot\ar[loop right,"8"]\ar[loop above,"4"]\ar[loop below,"F(2)\cdot F(3)=F(5)=32"]
@end@

@paragraph@
This represents how exponentiation turns multiplication into addition! Composition in these categories are addition and multiplication respectively, and the functor is raising 2 to a power, so the functors-preserve-composition equation becomes \\(2^{n+m}=2^n\cdot 2^m\\), a rule for exponentials we learn in high school!
@end@

@paragraph@
I find it helpful to remember that functors are just arrows in \\(\\texttt{Cat}\\). They're just transformations from collections of objects and morphisms to other collections of objects and morphisms, and we've attached a restriction to them that we've found useful and commonly-satisfied. A category of all small categories could be created where the arrows aren't functors, and functors aren't some new axiomatic thing in category theory. It's still all just objects and arrows, and functors are just an example of morphisms. They just feel different when we use them because we're not working in \\(\\texttt{Cat}\\) but *within some object* in \\(\\texttt{Cat}\\), so the arrows of \\(\\texttt{Cat}\\) have a sort of strange (but useful!) effect.
@end@

@paragraph@
In programming, as I mentioned before, we often deal with categories of collections. So an object (say, a set) contains elements within it. It's very important to keep in mind that functors just map objects to objects and can't touch the elements within at all. A functor might map the set \\(\\{4\\}\\) to the empty set \\(\\{\\}\\), and note that there isn't any function from \\(\\{4\\}\\) to the empty set, since there's no way to transform \\(4\\) into nothing! The real function is on the collections of objects (and morphisms), of which \\(\\{4\\}\\) and \\(\\{\\}\\) are just regular old members. This fact makes functors useful in programming. An "endofunctor" is a looping morphism in \\(\\texttt{Cat}\\), so it goes from a category back to the same category. A popular example in programming is the List functor, which maps any type `T` into the type of lists whose elements are of type `T`, called something like `List<T>`. Again, `T` could be `void` and this mapping is still perfectly fine, because we're just transforming types, not the values of those types. `List<void>` is a perfectly valid type and has exactly one value, namely `[]`. The List functor maps morphisms (functions) \\(f:T\\to U\\) to \\(\\texttt{map}\\;f:\\texttt{List}\\;T\\to\\texttt{List}\\;U\\), functions which apply \\(f\\) to each element in the list to produce a new list. That's something we do a lot in functional programming and I think that's awesome!
@end@

@paragraph@
\\(\\texttt{Cat}\\) has exponential objects too (objects representing arrows), called "functor categories." Remember, the objects of \\(\\texttt{Cat}\\) are categories, so exponential objects are categories. A functor category representing the arrows in \\(\\texttt{Cat}\\) from a category \\(C\\) to a category \\(D\\) is written \\([C,D]\\) (or, in typical exponential notation, \\(D^C\\)). The objects in such a category are functors from \\(C\\) to \\(D\\). The arrows transform one functor to another, and are called "natural transformations." Similar to how functors are like functions with an extra restriction that makes them useful, natural transformations are transformations that satisfy a "naturality condition," hence calling them "natural." Formally, for two functors \\(F,G:C\\to D\\), a natural transformation \\(\\alpha:F\\Rightarrow G\\) is a family of morphisms in \\(D\\) transforming "outputs" of \\(F\\) into "outputs" of \\(G\\). Namely, \\(\\alpha_X:FX\\to GX\\). So going back to the example of a addition monoid-based category \\(M_+\\) and a multiplication monoid-based category \\(M_\\cdot\\), \\(2^-,3^-:M_+\\to M_\\cdot\\) are two functors (each doing exponentiation) and if I map all the powers of two in \\(M_\\cdot\\) to the corresponding powers of three then that transforms \\(2^-\\) into \\(3^-\\). The naturality condition that natural transformations must satisfy is depicted below as a diagram that must commute, and also illuminates how the transformation works:
@end@   

@diagram@
    FX\ar[r,"Ff"]\ar[d,"\alpha_X"] & FY\ar[d,"\alpha_Y"] \\
    GX\ar[r,"Gf"] & GY
@end@

@paragraph@
That is, \\(Gf\\circ\\alpha_X=\\alpha_Y\\circ Ff\\). Note that this entire diagram takes place in \\(D\\), and the only mention of \\(C\\) are \\(X\\) and \\(Y\\), which are objects in \\(C\\).
@end@

@paragraph@
I've heard many times that being able to talk about and study natural transformations is the original "point" of category theory. Note once more that natural transformations, transforming functors into other functors, aren't some new special feature we just added to category theory. They're just arrows in categories! Not only that, but their abstract meaning in a functor category is more concrete in the categories functors act on, where they are just families of arrows. In functional programming we're quite comfortable with families of morphisms: they're (parametrically) polymorphic functions! Indeed, it's been proven that a parametrically-polymorphic function `f<T>: F<T> -> G<T>` (or, in a more Haskelly notation, `f :: F a -> G a`) satisfies the naturality condition and and is a natural transformation if `F` and `G` are functors. So the abstract-ness of natural transformations gets concrete pretty quickly in, say, a language like Haskell.
@end@

@paragraph@
One of the main reasons natural transformations felt like arcane magic to me for a long time was that people often draw them as arrows between arrows, like so:
@end@

@diagram@
    C\ar[r,bend left=50,""{name=U,below},"F"]\ar[r,bend right=50,""{name=D},"G"{below}] & D
    \ar[from=U,to=D,"\alpha"]
@end@

@paragraph@
This makes it appear as though there's some new thing we're allowed to do with categories, while in reality a natural transformation is just another regular morphism in some category somewhere. This notation does, however, help illustrate a complication with natural transformations: there are two different ways to compose them! "Vertical" composition is the kind you might expect:
@end@

@diagram@
    C\ar[rr,bend left=50,"F",""{below,name=U}]\ar[rr,""{name=M1},"G" near start,""{name=M2,below}]\ar[rr,bend right=50,""{name=D},"H"{below}] & & D
    \ar[from=U,to=M1,"\alpha"]
    \ar[from=M2,to=D,"\beta"]
@end@

@paragraph@
But there's also "horizontal" composition, which I could draw either of two ways:
@end@

@diagram@
    C\ar[r,bend left=50,""{name=U1,below},"F"]\ar[r,bend right=50,"G"{below},""{name=D1}] & D\ar[r,bend left=50,""{name=U2,below},"H"]\ar[r,bend right=50,""{name=D2},"K"{below}] & E 
    \ar[from=U1,to=D1,"\alpha"]
    \ar[from=U2,to=D2,"\beta"]
@end@

@paragraph@
@end@

@diagram@
    C\ar[rr,bend left=50,"H\circ F",""{name=U,below}]\ar[rr,bend right=50,"K\circ G"{below},""{name=D}] & & E
    \ar[from=U,to=D,"\beta\circ\alpha"]
@end@

@paragraph@
This is a powerful form of composition that gets used a lot but one that took me a while to wrap my head around. A composition of functors \\(H\\circ F\\) is just some functor out there, and so is \\(K\\circ G\\). They may behave quite differently from \\(H\\) or \\(F\\) or \\(K\\) or \\(G\\). It seems strange that transformations from \\(F\\) to \\(G\\) and \\(H\\) to \\(K\\) would be enough to find a natural transformation between these two mysterious functors. But indeed they are! Consider the natural transformation written "pointwise" or "by components:" \\(\\gamma_X:H(FX)\\to K(GX)\\). (\\(\\gamma\\) is what I'm calling the natural transformation \\(\\beta\\circ \\alpha\\).) If we think just for a moment for cases where objects are types and arrows are functions, this is a polymorphic function that takes a value of type `H (F a)` (using a Haskelly notation) and returns a value of type `K (G a)`. Available to us are two polymorphic functions `alpha: F a -> G a` and `beta: H a -> K a`. So we can define \\(\\gamma_X\\) as `gamma hfa = beta (fmap alpha hfa)` in Haskell, or \\(\\gamma_X=\\beta_X\\circ H\\alpha_X\\) in category theory notation. You could have instead done \\(\\gamma_X=K\\alpha_X\\circ \\beta_X\\), and because of the naturality condition these two definitions are equal. So we define the horizontal composition \\(\\beta\\circ\\alpha=\\gamma\\).
@end@

@paragraph@
Now one last tricky thing is that if we have two ways to compose, is the following diagram potentially ambiguous?
@end@

@diagram@
    X\ar[r,bend left=50,""{name=U1,below},"F"]\ar[r,""{name=UM1},""{name=DM1,below},"G" near start]\ar[r,bend right=50,""{name=D1},"H"{below}] & Y\ar[r,bend left=50,""{name=U2,below},"K"]\ar[r,""{name=UM2},""{name=DM2,below},"L" near start]\ar[r,bend right=50,""{name=D2},"M"{below}] & Z
    \ar[from=U1,to=UM1,"\alpha"] \ar[from=U2,to=UM2,"\gamma"]
    \ar[from=DM1,to=D1,"\beta"]  \ar[from=DM2,to=D2,"\delta"]
@end@

@paragraph@
We've got a square of natural transformations here, and it's unclear if we horizontally compose into a column first and then vertically compose, or if we vertically compose into a row first and then horizontally compose. Luckily, the naturality condition of natural transformations guarantees that either way produces the same result! Either way you end up with the same \\(K\\circ F\\to M\\circ H\\) natural transformation. This is called the Interchange Law, and it has some pretty cool consequences I'll get to in future posts.
@end@

@paragraph@
A popular example of natural transformations in a language like Haskell are monads. Note that my explanation here won't help much with understanding how to use monads in your code, I'm just discussing the math. A monad is an endofunctor \\(T:C\\to C\\) with two natural transformations \\(\\eta:id_C\\Rightarrow T\\) and \\(\\mu:T\\circ T\\Rightarrow T\\). There are also some conditions to satisfy, but let's start by unpacking just that much! \\(id_C\\) is an identity arrow in \\(\\texttt{Cat}\\), so it's a functor that maps every object and morphism in \\(C\\) into that same object or morphism. \\(T\\circ T\\) is the composition of \\(T\\) with itself, which is a thing you can do when an arrow loops from an object back to the same object (remember, \\(T\\) is an endofunctor, aka a looping arrow in \\(\\texttt{Cat}\\)). So we've got three functors we're talking about here (\\(id_C\\), \\(T\\), and \\(T\\circ T\\)) and two natural transformations to get between them. Now, the restrictions on these natural transformations are nicely illustrated in two commutating diagrams:
@end@

@diagram@
    T\ar[r,"\eta\circ id_T"]\ar[dr,<->,"="] & T\circ T\ar[d,"\mu"] & T\ar[l,"id_T\circ\eta"']\ar[ld,<->,"="'] \\
    & T &
@end@

@paragraph@
@end@

@diagram@
    T\circ T\circ T\ar[r,"id_T\circ\mu"]\ar[d,"\mu\circ id_T"] & T\circ T\ar[d,"\mu"] \\
    T\circ T\ar[r,"\mu"] & T
@end@

@paragraph@
Note that compositions in these arrows are compositions of natural transformations. In particular, they are *horizontal* compositions, which you can only really know by context. Recall that \\(id_C\\circ T=T\\), so \\(\\eta\\) transforms the implicit \\(id_C\\) into \\(T\\) and \\(id_T\\) (an identity arrow in the functor category \\([C,C]\\)) does nothing \\(T\\), so horizontally composed into \\(\\eta\\circ id_T\\) they transform \\(T\\) into \\(T\\circ T\\). If the arrow were a *vertical* composition instead, then it would mean \\(id_T\\) would transform \\(T\\) into \\(T\\) and then you'd do \\(\\eta\\) on \\(T\\), which makes no sense because \\(\\eta:id_C\\to T\\) and isn't an arrow coming out of \\(T\\). In the second diagram, \\(id_T\\circ\\mu:T\\circ T\\circ T\\to T\\circ T\\) might be more clear when written as \\(id_T\\circ\\mu:T\\circ(T\\circ T)\\to T\\circ T\\), which is equal because composition is associative.
@end@

@paragraph@
Sometimes writing natural transformations as \\(\\alpha_X: FX\\to GX\\) instead of \\(\\alpha:F\\to G\\) clarifies what's going on, making it feel more concrete. Note that in Haskell we'd write `return :: a -> T a` for some monad `T` instead of \\(\\eta:id_C\\to T\\), because we write natural transformations as polymorphic functions `alpha :: F a -> G a` and \\(id_C\\) applied to any type `a` is just equal to that same type `a`. And for \\(\\mu\\) we have the polymorphic function `join :: T (T a) -> T a` for any monad `T`.
@end@

@paragraph@
The last point I'll bring up about category theory on category theory is the notion of "enrichment." A typical category has sets \\(\\texttt{Hom}(X,Y)\\) of arrows going from any object \\(X\\) to any object \\(Y\\) (it might be the empty set if there are no such arrows). The fact that these collections of arrows are sets means a category is "locally small," and sometimes that's taken as part of the definition of a category. But the idea of a category can be generalized to have other kinds of collections for the arrows between objects. If the collection is a "class" and too big to form a set, then the category can be called "locally large," for example. When generalizing categories this way, we pick a category and say that these collections are objects in that category. For example, a locally small category (aka the normal kind) uses the category \\(\\texttt{Set}\\) of all sets (it's a large category), which means that the collections of arrows are sets. In this system, the idea of "homset" gets replaced with what are called "hom-objects," since they're objects in a category. You then say that locally small categories are "enriched over \\(\\texttt{Set}\\)." If the collection of arrows is a small category instead of a set, then you'd generally say the hom-objects are in \\(\\texttt{Cat}\\). Funnily enough, \\(\\texttt{Cat}\\) itself is an example of a category enriched over \\(\\texttt{Cat}\\)! That only means that the collections of functors between categories in \\(\\texttt{Cat}\\) are categories, not sets. (Also, \\(\\texttt{Set}\\) is enriched over \\(\\texttt{Set}\\), since function spaces \\(A\\to B\\) are just sets of functions.)
@end@

@paragraph@
Because \\(\\texttt{Cat}\\) is enriched over \\(\\texttt{Cat}\\), the arrows between two objects (categories) form a category, and we can say there are arrows between the arrows. That's what leads to the above notation of natural transformations as arrows between arrows. We call \\(\\texttt{Cat}\\) a "2-category" because there are arrows between the arrows, the idea being that a set is only objects and is a "0-category," and then adding arrows between objects is a "1-category." If you have arrows between arrows between arrows then it's a 3-category. Note that the category of 1-categories (which is \\(\\texttt{Cat}\\)) is a 2-category; the category of 2-categories is a 3-category and this pattern continues indefinitely. I'm told advanced researchers are studying \\(\\infty\\)-categories but we're well beyond what I know now!
@end@

@subheading@
Other important concepts
@end@

@paragraph@
It's unusual that I introduce natural transformations before universal constructions (like, say, a product). That choice has made some thing hard (I still owe you a formal definition of exponential objects!) but I think it does more good than bad, and I have enormous power to talk deeply about these other powerful concepts now, with the full weight of category theory.
@end@

@subheading@
Conclusion
@end@

@paragraph@
I should also mention the materials I came across. [https://youtube.com/playlist?list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_&](Bartosz Milewski) and [https://ncatlab.org/](nLab) are well-known resources that I found helpful, the first for its beginner-friendly nature and presentation of concepts in a proper order, and the second for details on particular concepts. Milewski also has a famous [https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/](blog), if you prefer the medium of text. I've also found Wikipedia to be helpful at times, in the same way as nLab, but it's known to be inaccurate for fuzzier/more-philosophical concepts like constructivism. Less well-known (but super valuable) resources are [https://youtube.com/playlist?list=PLCTMeyjMKRkqTM2-9HXH81tvpdROs-nz3](Richard Southwell) and [https://www.youtube.com/\@TheCatsters](the Catsters).
@end@