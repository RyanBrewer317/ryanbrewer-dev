<!doctype html>
<div><div><title>Implicit Products: A Better Type-Theoretic &quot;Forall&quot; - Ryan Brewer</title><meta name="description" content="Implicit products are a fascinating approach to universal quantification in dependent type theory, as well as proof irrelevance/erasure in compiler implementation."><script type="text/javascript" async="true" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script>
window.MathJax = {
  loader: {load: ['[tex]/unicode','[tex]/bussproofs']},
  tex: {packages: {'[+]': ['unicode','bussproofs']}},
};
        </script><script>hljs.highlightAll();</script></div><nav id="nav"><div id="nav-dropdown" onclick="document.getElementById(&#39;nav&#39;).classList.toggle(&#39;dropdown&#39;);document.body.classList.toggle(&#39;noscroll&#39;);">☰</div><a href="/" id="nav-home" onclick="document.body.classList.remove(&#39;noscroll&#39;);">Ryan Brewer</a><a href="/posts" id="nav-posts" onclick="document.body.classList.remove(&#39;noscroll&#39;);">Posts</a><a href="/wiki" id="nav-wiki" onclick="document.body.classList.remove(&#39;noscroll&#39;);">Wiki</a><a href="/contact" id="nav-contact" onclick="document.body.classList.remove(&#39;noscroll&#39;);">Contact</a><a href="/demos" id="nav-demos" onclick="document.body.classList.remove(&#39;noscroll&#39;);">Demos</a><a href="/feed.rss" id="nav-subscribe" onclick="window.location.href = &#39;/feed.rss&#39;"><img src="/rss-icon.png" id="rss-subscribe-icon">Subscribe</a></nav><div id="body"><h1>Implicit Products: A Better Type-Theoretic &quot;Forall&quot;</h1><div class="date">December 10, 2023</div><p><span>In this post I&#39;ll talk about a type theory idea that deserves more attention: implicit products. They came about in the 1998 dissertation of Alexandre Miquel, but for English speakers a common citation would be <a href="https://www.semanticscholar.org/paper/The-Implicit-Calculus-of-Constructions-Extending-an-Miquel/990f8f44e011192122dfd35617f8cabf08052d60"><span>The Implicit Calculus of Constructions</span></a>. They are used most notably in the <a href="https://cedille.github.io/"><span>Cedille</span></a> proof assistant.
</span></p><p><span>This post assumes familiarity with logic (including the universal quantifer &quot;for all&quot;), <a href="/posts/logic-in-types.html"><span>dependent types</span></a>, very basic set theory, and the \(\lambda\)-calculus.
</span></p><h3><span>What is it?
</span></h3><p><span>For a moment, you&#39;ll have to ignore the strange name <i><span>implicit product.</span></i> It makes a lot of sense once you know how they&#39;re used, but I&#39;ll get to that later. Think of an implicit product like a universal quantifer (&quot;for all&quot;) in logic. It&#39;s written like:
</span></p><div class="math-block">\[\forall x: A. B(x)
\]</div><p><span>where \(A\) is a type (proposition) and \(B\) is a type that may refer to \(x\) (predicate). An implicit product is a type that is inhabited if \(B(x)\) is inhabited for every \(x\) in \(A\).
</span></p><p><span>In the most recent iterations of the theory, you make a value of this type by writing \(\Lambda x: A. e\) where, crucially, \(x\) can appear in the types in \(e\) but not in anything that could stick around &#39;til runtime. That is, if you erase all the types of \(e\), the \(x\) isn&#39;t used in it at all. To use such a term \(\Lambda x: A. e\) you call it like a \(\lambda\)-abstraction. For the purpose of type-inference you might mark the call with some additional symbol to make it clear that the function is a \(\Lambda\)-abstraction and not a \(\lambda\)-abstraction.
</span></p><h3><span>Infinite Intersection
</span></h3><p><span>On the surface this might just seem like a worse \(\Pi\)-type, which is the usual &quot;for all&quot; in something like Coq, Agda, or Lean. The only real difference, from what I&#39;ve said so far, is that the parameter of the abstraction isn&#39;t used at runtime. But this makes all the difference. 
</span></p><p><span>A \(\Pi\)-type represents &quot;for all&quot; in a strange, roundabout way: it&#39;s a function (implication) from <i><span>data</span></i> (not a proposition) to a proposition about that data, and can only be constructed if every proposition it returns can be constructed given the data of that proposition.
</span></p><p><span>When you learn about &quot;for all&quot; and &quot;there exists&quot; in logic, that isn&#39;t at all how you normally learn it. Instead, &quot;for all&quot; is seen as a possibly-infinite conjunction for every element of a possibly-infinite domain. &quot;There exists&quot; is, dually, a possibly-infinite <i><span>disjunction</span></i> for every element of a possibly-infinite domain. \(\Sigma\)-types can kind of be seen that way for existential quantification, but \(\Pi\)-types definitely can&#39;t, because again, they&#39;re a bit like an implication from a non-proposition. They work for doing logic, of course; they&#39;re just a little weird.
</span></p><p><span>Implicit products fix this. An implicit product is a possibly-infinite <i><span>intersection</span></i> (conjunction) of all the possible &quot;return types.&quot; \(\forall x: A. B(x)\) is an intersection of all types \(B(x)\) for each \(x\) in \(A\).
</span></p><p><span>What&#39;s an intersection type? They&#39;re what you get when you say that a term (say, \(e\)) could have one type (say, \(A\)) or another type (say, \(B\)). Then you might say \(e: A\cap B\), that is, \(e\) is in the <i><span>intersection</span></i> between the types \(A\) and \(B\). This isn&#39;t the standard way of doing conjunction in logic (pairs/structs/records/tuples are), but it should be clear that if \(A\cap B\) has a value in it (and is therefore &quot;true&quot;), then \(A\) and \(B\) also have values in them (are &quot;true&quot;), namely that same value in their intersection. So it acts like a conjunction here.
</span></p><p><span>But wait, if it&#39;s just an intersection of all the return types, it&#39;s not really a function, right? How is that possible? We literally have calls to \(\Lambda\)-abstractions! The secret is, since they don&#39;t use their parameter for evaluation, it&#39;s perfectly fine to evaluate them with no argument at all! (In the absense of side-effects, of course.) At runtime, \((\Lambda x: A. \lambda y: B. e)(a)(b)\) evaluates as \((\lambda y. e)(b)\). Therefore, values of type \(\forall x: A. B(x)\) execute as some kind of \(B\), and we know that its argument (\(x\)) doesn&#39;t matter.
</span></p><p><span>Implicit products are generalization in their truest form: some aspect of a value could work for multiple types, so the type gets replaced with a type variable, and the whole type becomes an intersection of all the possible instantiations of that type variable. This is why I argue that implicit products make for a &quot;better&quot; interpretation of the universal quantifier than \(\Pi\)-types.
</span></p><h3><span>What&#39;s with that name though?
</span></h3><p><span>The other reason implicit products are interesting is from a compiler engineering perspective. When developing a dependently typed language, a huge optimization to make is erasing the proofs at runtime, much like one erases the types at runtime. The only thing that should remain are values of actual <i><span>data</span></i>types, like <code><span>int</span></code>, as opposed to proofs of propositions (which are technically still values of types).
</span></p><p><span>To that end, languages like Idris and Agda, and the extraction of OCaml code from Coq code, have put a lot of effort into <i><span>proof irrelevance,</span></i> the property that proofs don&#39;t affect runtime execution. Idris has Quantitative Type Theory for this, which allows it to say that the variables bound by some \(\lambda\)-abstractions aren&#39;t used &quot;relevantly&quot; in the body of the abstraction. That is, it can be used in things that get erased, but nothing that makes it to runtime. Sound familiar? These &quot;0-quantity&quot; \(\lambda\)-abstractions are very similar to implicit products. The only real difference is that they&#39;re philosophically still functions, not giant intersections. The erasure of the argument is an optimization, nothing more. Regardless, this similarity shows how using implicit products in your language automatically gives you a big optimization.
</span></p><p><span>The &quot;0-quantity&quot; \(\lambda\)-abstractions of Idris&#39; QTT are called &quot;implicit.&quot; This is a common term for arguments that we expect to disappear at runtime. There is the risk of confusion with another meaning for &quot;implicit&quot; in this context: arguments which you *don&#39;t<i><span> write but which (possibly) </span></i>are<i><span> present at runtime. This kind of &quot;implicit&quot; is a basic form of type inference for dependently typed languages. If you have a polymorphic identity function \(id=\lambda t: </span></i>.\lambda x: t. x\) then you&#39;d like to be able to call it like \(id(7)\) instead of \(id(\mathbb{N})(7)\), but you would consider this a notational shorthand, nothing more. That&#39;s called an &quot;implicit&quot; argument but it isn&#39;t the type of &quot;implicit&quot; we consider here for implicit products.
</span></p><p><span>So now we know why they&#39;re called <i><span>implicit</span></i> products. Why are they called implicit <i><span>products?</span></i>
</span></p><p><span>This might be a more basic point for those quite familiar with dependent types, but it&#39;s an easy source of confusion so I figured I&#39;d touch on it anyway. In general in type theory, a product is a type of tuple: the product of \(\mathbb{N}\) and \(\mathbb{Z}\) is the type of pairs of natural numbers and integers, and is written \(\mathbb{N}\times\mathbb{Z}\). It&#39;s a Cartesian product, to use a term more broadly familiar. This is really confusing because \(\Pi\)-types are often referred to as &quot;products,&quot; or &quot;dependent product types,&quot; as well as being called &quot;dependent function types.&quot; My understanding for why this is the case is that we can think of a tuple (an element of a product type) as a function from \(\mathbb{N}\) to values of various types. These are &quot;indexed&quot; by the natural number given. So \((5, {4})\) is a tiny function mapping \(0\) to \(5\) and \(1\) to \({4}\). The return type of this function depends on the integer given as its argument: it&#39;s a dependent function type! A \(\Pi\)-type indexes values of various types (the family of return types) using the values of the argument type. It is this function-type meaning of &quot;product&quot; that is used in the term &quot;implicit product.&quot;
</span></p><h3><span>Conclusion
</span></h3><p><span>That&#39;s all I have to say about implicit products for now. I think they&#39;re a really cool idea and I&#39;m adding them to my own dependently-typed language <a href="https://github.com/RyanBrewer317/Saber"><span>Saber</span></a>. If you want to play with a finished implemenation, though, the most famous by far would be <a href="https://cedille.github.io/"><span>Cedille</span></a>.
</span></p></div><div><p id="copyright-notice" class="subtle-text">© 2024 Ryan Brewer.</p><script src="/__/firebase/8.10.1/firebase-app.js"></script><script src="/__/firebase/8.10.1/firebase-analytics.js"></script><script src="/__/firebase/init.js"></script><script>firebase.analytics();</script></div></div>